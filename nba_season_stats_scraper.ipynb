{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f42d03b0",
   "metadata": {},
   "source": [
    "## Getting the Website Source Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1b49fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "PATH = '/Users/andrewlee/chromedriver'\n",
    "service = Service(PATH)\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "driver.get(\"https://nba.com/players\")\n",
    "\n",
    "wait = WebDriverWait(driver, 60)\n",
    "\n",
    "# Wait for the title element to appear before continuing\n",
    "title_element = wait.until(EC.presence_of_element_located((By.TAG_NAME, \"title\")))\n",
    "\n",
    "# Select \"All\" option from dropdown\n",
    "dropdown_element = driver.find_element(By.XPATH, \"//select[@title='Page Number Selection Drown Down List']\")\n",
    "dropdown = Select(dropdown_element)\n",
    "dropdown.select_by_visible_text(\"All\")\n",
    "\n",
    "# Wait for the dropdown element to be updated\n",
    "updated_dropdown_element = wait.until(EC.visibility_of_element_located((By.XPATH, \"//select[@title='Page Number Selection Drown Down List']\")))\n",
    "\n",
    "# Get the page source after the dropdown has been updated\n",
    "page_source = driver.page_source\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f40d142",
   "metadata": {},
   "source": [
    "## Converting the Source Code Into a BS Object and Grabbing Links/Player Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "442c6772",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import re\n",
    "\n",
    "current_player = []\n",
    "names = []\n",
    "\n",
    "soup = bs(page_source, 'html.parser')\n",
    "\n",
    "# filtering out the elements which do not contain player names or links\n",
    "player_names = soup.find_all(class_=\"RosterRow_playerName__G28lg\")\n",
    "player_links = soup.find_all(class_=\"Anchor_anchor__cSc3P RosterRow_playerLink__qw1vG\")\n",
    "\n",
    "for link in player_links:\n",
    "    href = link.get(\"href\")\n",
    "    current_player.append(href)\n",
    "\n",
    "# function to fix links\n",
    "def fix_link(string):\n",
    "    pattern = r'(/.*/[^/]+/).*'\n",
    "    result = re.sub(pattern, r'\\1', string)\n",
    "    return \"https://nba.com/stats\" + result.rstrip('/')\n",
    "\n",
    "# create a list of player links with fixed format\n",
    "player_links_fixed = [fix_link(link) for link in current_player]\n",
    "\n",
    "for player in player_names:\n",
    "    full_name = \"-\".join(player.stripped_strings)\n",
    "    full_name = full_name.replace(\" \", \"-\")\n",
    "    names.append(full_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e36e10",
   "metadata": {},
   "source": [
    "## Grabbing Data from Player Stats Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc259c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import re\n",
    "\n",
    "player_figs = []\n",
    "no_stat_players = []\n",
    "stat_names = ['+/-',  '3P%',  '3PA',  '3PM',  'APG',  'AST',  'BLK',  'BPG',  'FG%',  'FGA',  'FGM',  'FT%',  'FTA',  'FTM',  'GP',  'MIN',  'MPG',  'PF',  'PPG',  'PTS',  'REB',  'RPG',  'SEASON',  'SPG',  'STL',   'TOV',  'TPG', 'TM']\n",
    "\n",
    "# Gets the text out the parenthesis\n",
    "def extract_text_within_parentheses(string):\n",
    "    match = re.search(r'\\((.*?)\\)', string)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "\n",
    "# Storing/Making the links for the player stats\n",
    "muse_links = []\n",
    "for player in names:\n",
    "        muse_links.append(f\"https://www.statmuse.com/nba/ask/{player}-career-stats\")\n",
    "\n",
    "def get_player_figs(player_links_fixed, names):\n",
    "# Send get request to get basic player information\n",
    "    for index, test in enumerate(player_links_fixed):\n",
    "        temp_figs = []\n",
    "        r = requests.get(test)\n",
    "        test_r = bs(r.content)\n",
    "\n",
    "# Ensuring that players with no stats are not added to the dataset \n",
    "        try:\n",
    "            pie = test_r.find_all(class_=\"PlayerSummary_playerStatValue___EDg_\")[3].text\n",
    "        except IndexError:\n",
    "            no_stat_players.append(names[index])\n",
    "            continue\n",
    "        \n",
    "# Grabbing element that contains the basic player info and storing that info\n",
    "        player_fax_html = test_r.find_all(class_=\"PlayerSummary_playerInfoValue__JS8_v\")\n",
    "\n",
    "        for i in range(0,8):    \n",
    "            temp_figs.append((player_fax_html[i].text))\n",
    "\n",
    "        for i in range(0,2):\n",
    "            temp_figs[i] = extract_text_within_parentheses(temp_figs[i])\n",
    "\n",
    "            if i == 0:\n",
    "                temp_figs[i] = temp_figs[i][0:(len(temp_figs[i])-1)]\n",
    "            elif i == 1:\n",
    "                temp_figs[i] = temp_figs[i][0:(len(temp_figs[i])-2)]\n",
    "\n",
    "# Sending request to get actual player stats\n",
    "        if len(temp_figs) == 8 and names[index]:\n",
    "            temp_figs.append(names[index])\n",
    "            \n",
    "            stat_muse = requests.get(muse_links[index])\n",
    "            muse_html = stat_muse.content\n",
    "            \n",
    "            soup2 = bs(muse_html, 'html.parser')\n",
    "            stats_json_html = soup2.find(\"visual-answer\")['answer']\n",
    "            \n",
    "            stats_json = json.loads(stats_json_html)\n",
    "            \n",
    "            season_stats = stats_json[\"visual\"][\"detail\"][0][\"grids\"][0][\"rows\"]\n",
    "            \n",
    "# Adding the complete player info to the final dataset        \n",
    "            if \"SEASON\" in season_stats[0]:\n",
    "                for season in season_stats:\n",
    "                    temp_statz = []\n",
    "                    for stat_type in stat_names:\n",
    "                        temp_statz.append(season[stat_type][\"display\"])\n",
    "                    player_figs.append(temp_figs+temp_statz)\n",
    "        temp_figs = []\n",
    "\n",
    "get_player_figs(player_links_fixed, names)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42444f9a",
   "metadata": {},
   "source": [
    "## Saving the Dataset as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2e586cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "player_figs_header = ['HEIGHT', 'WEIGHT', 'COUNTRY', 'LAST ATTENDED', 'AGE', 'BIRTHDATE', 'DRAFT', 'EXPERIENCE', 'NAME', '+/-',  '3P%',  '3PA',  '3PM',  'APG',  'AST',  'BLK',  'BPG',  'FG%',  'FGA',  'FGM',  'FT%',  'FTA',  'FTM',  'GP',  'MIN',  'MPG',  'PF',  'PPG',  'PTS',  'REB',  'RPG',  'SEASON',  'SPG',  'STL',   'TOV',  'TPG', 'TM']\n",
    "\n",
    "# create DataFrame\n",
    "df = pd.DataFrame(player_figs, columns=player_figs_header)\n",
    "\n",
    "# print DataFrame\n",
    "df.to_csv('player_stats_updated2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
